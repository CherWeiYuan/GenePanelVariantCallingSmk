# Snakemake variant calling pipeline for gene panel
# snakemake --cores 10 --use-conda --resources mem_mb=20000 --retries 3

# Important information
#   Pipeline is engineered for GRCh38 reference genome
#   Input files have the following nomenclature:
#       Read 1: {sample_name}_R1_001.fastq.gz
#       Read 2: {sample_name}_R2_001.fastq.gz

configfile: "workflow/config.yaml"

# Get working directory
from os import getcwd
working_directory = getcwd()

# Get prefix of fastq files
from os import listdir
from sys import exit
sample_names = []
for name in listdir("fastq"):
    if "_R1_001.fastq.gz" in name:
        sample_names.append(name[:-16])
    elif "_R2_001.fastq.gz" in name:
        sample_names.append(name[:-16])
    else:
        exit("Please format fastq file name as " +\
        "{sample}_R1_001.fastq.gz & {sample}_R2_001.fastq.gz" +\
        "for read 1 and read 2 & respectively")
sample_names = list(set(sample_names))

rule all:
    input:
        "multiqc_report.html"

rule fastp:
    input:
        read1="fastq/{sample}_R1_001.fastq.gz",
        read2="fastq/{sample}_R2_001.fastq.gz"
    output:
        read1=temp("clean_fastq/clean_{sample}_R1_001.fastq.gz"),
        read2=temp("clean_fastq/clean_{sample}_R2_001.fastq.gz"),
        report="results/quality_control/{sample}.fastp.html",
        json="results/quality_control/{sample}.fastp.json"
    conda:
        "envs/fastp.yaml"
    threads:
        config["threads"]
    shell:
        "fastp -i {input.read1} -I {input.read2} "
        "-o {output.read1} -O {output.read2} "
        "-h {output.report} -j {output.json} "
        "--detect_adapter_for_pe --qualified_quality_phred 15 "
        "--unqualified_percent_limit 40 --length_required 15 "
        "--thread {threads}"

rule bwa:
    input:
        read1="clean_fastq/clean_{sample}_R1_001.fastq.gz",
        read2="clean_fastq/clean_{sample}_R2_001.fastq.gz"
    params:
        genome="resources/genome/Homo_sapiens_assembly38.fasta"
    output:
        temp("sam/{sample}.sam")
    conda:
        "envs/bwa.yaml"
    threads:
        config["threads"]
    shell:
        "bwa mem -t {threads} {params.genome} {input.read1} {input.read2} > "
        "{output}"

rule addreadgroup:
    input:
        "sam/{sample}.sam"
    params:
        rgid=config["rgid"],
        rglb=config["rglb"],
        rgpl=config["rgpl"],
        rgpu=config["rgpu"]
    output:
        temp("sam/{sample}.RG.sam")
    conda:
        "envs/gatk4.yaml"
    shell:
        "gatk AddOrReplaceReadGroups "
        "-I {input} -O {output} -RGID {params.rgid} -RGLB {params.rglb} "
        "-RGPL {params.rgpl} -RGPU {params.rgpu} -RGSM {wildcards.sample}"

rule sortsam:
    input:
        "sam/{sample}.RG.sam"
    output:
        temp("bam/{sample}.sorted.bam")
    conda:
        "envs/samtools.yaml"
    threads:
         config["threads"]
    shell:
        "samtools sort -l 0 -o {output} -O BAM --threads {threads} {input}" 

rule markduplicates:
    input:
        "bam/{sample}.sorted.bam"
    output:
        bam="bam/{sample}.sorted.removed_duplicates.bam",
        metrics="results/quality_control/markduplicates/{sample}.txt"
    conda:
        "envs/gatk4.yaml"
    shell:
        "gatk MarkDuplicates -I {input} -O {output.bam} "
        "-M {output.metrics} --REMOVE_DUPLICATES "
        "--REMOVE_SEQUENCING_DUPLICATES"

rule bamindex:
    input:
        "bam/{sample}.sorted.removed_duplicates.bam"
    output:
        "bam/{sample}.sorted.removed_duplicates.bam.bai"
    conda:
        "envs/samtools.yaml"
    shell:
        "samtools index {input} {output}"

rule deepvariant:
    input:
        bam="bam/{sample}.sorted.removed_duplicates.bam",
        bai="bam/{sample}.sorted.removed_duplicates.bam.bai" 
    params: 
        genome="resources/genome/Homo_sapiens_assembly38.fasta",
        bed=config["intervals_list"]
    output:
        outvcf="vcf/{sample}.dv.vcf"
    threads: 1
    shell:
        "docker run --rm -v '{working_directory}:/input' "
        "-v '{working_directory}:/output' "
        "google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant "
        "--model_type=WGS --ref=/input/{params.genome} "
        "--reads=/input/{input.bam} --output_vcf=/output/{output} "
        "--regions=/input/{params.bed} --num_shards={workflow.cores} "
        "--num_shards 1"

rule spliceai:
    input:
        "vcf/{sample}.dv.vcf"
    params:
        genome="resources/genome/Homo_sapiens_assembly38.fasta"
    output:
        "vcf/spliceai/{sample}.spliceai.vcf"
    conda:
        "envs/spliceai_gpu.yaml"
    shell:
        "spliceai -I {input} -O {output} -R {params.genome} -A grch38 -M 1"

rule bgzip_spliceai:
    input:
        "vcf/spliceai/{sample}.spliceai.vcf"
    output:
        "vcf/spliceai/{sample}.spliceai.vcf.gz",
    conda:
        "envs/samtools.yaml"
    shell:
        "bgzip -c {input} > {output}"

rule tabix_spliceai:
    input:
        "vcf/spliceai/{sample}.spliceai.vcf.gz"
    output:
        "vcf/spliceai/{sample}.spliceai.vcf.gz.tbi"
    conda:
        "envs/samtools.yaml"
    shell:
        "tabix -f {input}"

rule vep_tsv:
    input:
        vcf="vcf/spliceai/{sample}.spliceai.vcf",
        vcfgz="vcf/spliceai/{sample}.spliceai.vcf.gz",
        vcftbi="vcf/spliceai/{sample}.spliceai.vcf.gz.tbi",
    params:
        genome="resources/genome/Homo_sapiens_assembly38.fasta"
    output:
        out_tsv="vcf/vep/{sample}.vep.tsv",
        report="results/vep_annotation/{sample}_variants_summary.html"
    conda:
        "envs/vep_108.yaml"
    shell:
        "vep -i {input.vcf} --output_file {output.out_tsv} "
        "--stats_file {output.report} --cache "
        "--dir_cache resources/vep_cache --tab " 
        "--species 'homo_sapiens' --force_overwrite --symbol --biotype "
        "--canonical --variant_class --sift b --polyphen b --humdiv "
        "--gene_phenotype --regulatory --numbers --mirna --protein --domains "
        "--af --af_1kg --af_gnomade --af_gnomadg --individual all --mane "
        "--show_ref_allele --fasta {params.genome} --hgvs --hgvsg --offline "
        "--custom resources/vep_cache/ClinVar/clinvar.vcf.gz,"
        "ClinVar,vcf,exact,0,ClinVar,vcf,exact,0,AF_ESP,AF_EXAC,"
        "AF_TGP,ALLELEID,CLNDN,CLNDNINCL,CLNDISDB,CLNDISDBINCL,CLNHGVS,"
        "CLNREVSTAT,CLNSIG,CLNSIGCONF,CLNSIGINCL,CLNVC,CLNVCSO,CLNVI,DBVARID,"
        "GENEINFO,MC,ORIGIN,RS,SSR "
        "--custom {input.vcfgz},SpliceAI,vcf,exact,0,SpliceAI"

rule finis:
    input:
        "vcf/vep/{sample}.vep.tsv"
    output:
        full="results/variants/all_data/{sample}.full.csv",
        simple="results/variants/simplified_data/{sample}.simple.csv"
    conda:
        "envs/finis.yaml"
    shell:
        "python3 resources/finis/finis.py --vcf_tsv {input} "
        "--out_full {output.full} --out_simple {output.simple}"

rule multiqc:
    input:
        expand("results/variants/simplified_data/{sample}.simple.csv", sample = sample_names)
    output:
        "multiqc_report.html"
    conda:
        "envs/multiqc.yaml"
    shell:
        "multiqc --force --ignore resources ."

onsuccess:
    print("Workflow finished, no error")
